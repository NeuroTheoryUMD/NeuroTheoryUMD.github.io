<!doctype html>
<html>
<head>
	<meta charset="UTF-8">
	<title>NeuroTheory Lab Research</title>
	<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700">
	<link rel="stylesheet" href="../NTlab_styles.css">
</head>
	
<body>
	<!-- Header -->
	<header>
		<a class="site-logo" href="index.html">
			<img src="../Images/NTlabBackStrip.jpg" width="100%">
			<div class="NTlab"><h1>NeuroTheory Lab Research</h1></div>

			<nav class="site-nav">
				<ul class="menu">
					<li><a class="menu_alt" href="../code.html"><h3>Code</h3></a></li>
					<li><a class="menu_alt" href="../presentations.html"><h3>Presentations</h3></a></li>
					<li><a class="menu_alt" href="../publications.html"><h3>Publications</h3></a></li>
					<li><a class="menu_alt" href="../people.html"><h3>People</h3></a></li>
					<li><a class="menu_alt" href="../research.html"><h3><span style="color:#060265"><u>Research</u></span></h3></a></li>
				</ul>
			</nav>
		</a>
	</header>
	
	<!-- Main content -->
	<main>
		<section class="intro">
			<h1>Cortical processing of vision</h1>
			<h3>Color vision</h3>
			<p>Color and form are often treated as separable features of an image. One can recognize shapes in achromatic photographs and conceptualize the color of an object abstracted from shape. Yet color-specific processing is embedded throughout the visual pathway from the first stage of the visual pathway, where three different types of light sensors (“cones”) with sensitivity to different parts of the visual spectrum initially convert light into electrical impulses. The color of a given point can in principle be determined by comparing the activation of the three different cone types, but the separate color channels are maintained until the primary visual cortex (V1), where they are finally combined in neurons that concurrently have sensitivity to different spatial patterns. Indeed, while it was initially thought that color and form were processed through separate pathways within V1, recent experiments have highlighted that a surprising fraction of V1 neurons mixes them together in a diversity of ways. Exactly how the mixing occurs, and for what purpose, are critical open questions in understanding human vision, and have been difficult to answer because such mixing is too complicated to characterize using traditional approaches. This project will combine large-scale recording of V1 neural activity during tailored “spatio-chromatic” visual stimulation with new computational approaches, which will both offer an unprecedented high-resolution description of color processing within V1, while determining the underlying function of spatio-chromatic mixing in supporting natural color vision.	
			</p>
			<p><i>Experimental collaborator</i>: <a href="https://www.nei.nih.gov/research/research-labs-and-branches/we-are-nei-intramural/bevil-conway" target="_new">Bevil Conway</a> (NEI)</p>
			<ul>
				<li>Recent <a href="../PresentationFiles/CRCNS2022Bartsch_poster.pdf" target="_new">poster</a> presenting current progress at the CRCNS PIs Meeting 2022  (Atlanta, GA)</p></li>
				<li>An initial <a href="../PresentationFiles/VSS2022_Bartsch_poster.pdf" target="_new">poster</a> presenting preliminary work presented at the Visual Sciences Society (VSS) 2022 Conference (St. Petersberg, FL)</p></li>
			</ul>
			
			<h3>Binocular integration and disparity selectivity</h3>
			<p>Despite having two distinct visual sensors — the eyes — visual perception usually consists of a single fused image. This requires the visual system to combine disparate “monocular” information from each retina into a “binocular” representation: a process thought to largely occur in the primary visual cortex (V1), whose inputs from the LGN are monocular, and its outputs are largely binocular. Combining information from both eyes is not trivial, because objects at different depths will have binocular disparity, that is, they will have a shifted position in both eyes. The visual system must therefore take disparity into account when combining information from each eye, and indeed V1 has a large number of disparity-tuned neurons. However, despite a number of conceptual models for how disparity processing *should* occur, no model thus far has been able to adequately reproduce the disparity tuning of V1 neurons using modern physiological approaches.</p>

			<p><i>Experimental collaborator</i>: <a href="https://www.nei.nih.gov/research/research-labs-and-branches/we-are-nei-intramural/bruce-cumming" target="_new">Bruce Cumming</a> (NEI)</p>
			<ul>
				<li><b>[SFN 2021]</b> Binocular integration as nonlinear mixing: how binocular neurons in primary visual cortex preserve eye-specific information for downstream visual processing, <i>presented by Ethan Cheng</i> [<a href="../PresentationFiles/SFN2021_Cheng_slides.pdf" target="_new">Slides</a>] [<a href="../PresentationFiles/SFN2021_Cheng_video.mp4" target="_new">Video summary</a>]</li>
				<li><b>[SFN 2021]</b> Amplification of disparity selectivity by spatial convolutions in the primary visual cortex, <i>presented by Felix Bartsch</i> [<a href="../PresentationFiles/SFN2021_Bartsch_slides.pdf" target="_new">Slides</a>] [<a href="../PresentationFiles/SFN2021_Bartsch_video.mp4" target="_new">Video summary</a>]</li>
				<li>Henriksen S, <b>Butts DA</b>, Read JCA, Cumming BG (2018) Current models cannot account for V1's specialisation for binocular natural image statistics. <i>bioRxiv</i>: 497008.  [<a href="https://www.biorxiv.org/content/10.1101/497008v1" target="_new">Preprint</a>]</li>

			</ul>
		</section>
			</main>
</body>
</html>
